{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>logistic regression</h1>\n",
    "# setting training set labels to 50/50 %\n",
    "    <p>160 class 0 samples by adding 70 class 0 records\n",
    "it should adjust the features of the added function\n",
    "<br> <li>adjust the added sample with percentage adjustment</li>\n",
    "<br> <li>try to compute standard devation to remove some unnecessary features</li>\n",
    "<h4>score: private --- ; public--</h4>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>step1: <b>Pre-process training data</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def randomInteger(a, b):\n",
    "    return random.randint(a, b)\n",
    "\n",
    "def adjustValue(value, percentageValue):    # 0 to xx.x%\n",
    "    return_value = value\n",
    "    plusORminus = randomInteger(0, 1) # 0 is plus, 1 is minus\n",
    "\n",
    "    if (plusORminus == 0):\n",
    "        return_value += value*(randomInteger(0, percentageValue)/1000)\n",
    "    else:\n",
    "        return_value -= value*(randomInteger(0, percentageValue)/1000)\n",
    "\n",
    "    if (np.isnan(return_value)):\n",
    "        print(\"NaN - value*(randomInteger(0, percentageValue)/1000): \", value*(randomInteger(0, percentageValue)/1000))\n",
    "    \n",
    "    return return_value \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operation\n",
    "\n",
    "adding_sample_on_class_0 = False\n",
    "adjusted_percentage_range = 5.5 # best result is 5.5%\n",
    "\n",
    "implement_feature_reduction = True\n",
    "feature_reduction_threshold = 0.82\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " df_class_1 filter():\n",
      "\n",
      " df_class_2 filter():\n",
      "\n",
      "remaining_features:  ['167', '226', '231', 'target']\n",
      "list Length:  4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# df = pd.read_csv('./train.csv', index_col = True)\n",
    "url = 'https://raw.githubusercontent.com/lucascheng24/comp4432ML-Dont-over-fit-II/main/train.csv'\n",
    "df = pd.read_csv(url, index_col=\"id\")\n",
    "df['target'] = df['target'].astype(int)\n",
    "\n",
    "parameters_dictionary = {}\n",
    "\n",
    "df_class_1 = df[df['target'] == 1]\n",
    "df_class_0 = df[df['target'] == 0]\n",
    "\n",
    "sd_class_1 = df_class_1.std()\n",
    "sd_class_2 = df_class_0.std()\n",
    "\n",
    "remaining_features = {\"target\"}\n",
    "\n",
    "# df_class_1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n df_class_1 filter():\")\n",
    "\n",
    "\n",
    "for i in range(300):\n",
    "    str_i = str(i)\n",
    "    # print(i, \": \", sd_class_1[str_i])\n",
    "    if (sd_class_1[str_i] < feature_reduction_threshold):\n",
    "        # counter += 1\n",
    "        # print(i, \": \", sd_class_1[str_i])\n",
    "        remaining_features.add(str_i)\n",
    "\n",
    "# sd_class_1['5']\n",
    "# print(sd_class_1.filter(items > 1.05))\n",
    "\n",
    "\n",
    "counter_2 = 0\n",
    "print(\"\\n df_class_2 filter():\")\n",
    "\n",
    "for i in range(300):\n",
    "    str_i = str(i)\n",
    "    # print(i, \": \", sd_class_1[str_i])\n",
    "    if (sd_class_2[str_i] < feature_reduction_threshold):\n",
    "        # counter_2 += 1\n",
    "        # print(i, \": \", sd_class_2[str_i])\n",
    "        remaining_features.add(str_i)\n",
    "\n",
    "\n",
    "print(\"\\nremaining_features: \", sorted(remaining_features))\n",
    "print(\"list Length: \", len(remaining_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the column according the <remaining_features>\n",
    "\n",
    "list_remainingFeatures = list(remaining_features)\n",
    "# list_remainingFeatures\n",
    "\n",
    "\n",
    "df_class_1 = df_class_1[list_remainingFeatures]\n",
    "\n",
    "df_class_0 = df_class_0[list_remainingFeatures]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 : 90\n",
      "160 : 90\n",
      "Number of NaN values present: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(df_class_1), \":\", len(df_class_0))\n",
    "\n",
    "more_class_0 = df_class_0.sample(n=70)\n",
    "more_class_0 = more_class_0.reset_index()\n",
    "\n",
    "# random the new class(0) data\n",
    "index = 0\n",
    "feature_index = 0\n",
    "\n",
    "for i in range(len(more_class_0['target'])):\n",
    "    # print(row)\n",
    "    for column_name in more_class_0:\n",
    "        more_class_0.at[i, column_name] = adjustValue(more_class_0.at[i, column_name], adjusted_percentage_range*10)\n",
    "        # if (np.isnan(more_class_0.at[i, str(j)])):\n",
    "        #     print(\"NaN index;column :\", i, \";\", j)\n",
    "        # item[str(i)] = adjustValue(item[str(i)], 100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # index = randomInteger(0, 159)\n",
    "    # feature_index = randomInteger(0, 299)\n",
    "\n",
    "\n",
    "more_class_0 = more_class_0.drop(columns=['id'])\n",
    "\n",
    "if adding_sample_on_class_0:\n",
    "    df_class_0 = pd.concat([df_class_0, more_class_0])\n",
    "\n",
    "# df_class_0 = more_class_0.reset_index()\n",
    "\n",
    "\n",
    "df = pd.concat([df_class_0, df_class_1])\n",
    "\n",
    "# df = df.reset_index()\n",
    "\n",
    "# print(df)\n",
    "\n",
    "df.reset_index()\n",
    "\n",
    "df.rename(columns = {'index': 'id'})\n",
    "\n",
    "print(len(df_class_1), \":\", len(df_class_0))\n",
    "\n",
    "for element in df:\n",
    "    if element != \"target\":\n",
    "        parameters_dictionary.update({element : df[element]})\n",
    "\n",
    "\n",
    "\n",
    "label_dictionary = {'label': df['target']}\n",
    "\n",
    "df_X = pd.DataFrame(data = parameters_dictionary)\n",
    "df_Y = pd.DataFrame(data = label_dictionary)\n",
    "\n",
    "# print(df_X['id'])\n",
    "\n",
    "# applying the method\n",
    "nan_in_df = df_X.isnull().sum().sum()\n",
    " \n",
    "# printing the number of values present in\n",
    "# the whole dataframe\n",
    "print('Number of NaN values present: ' + str(nan_in_df))\n",
    "# print(df_class_0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement logistic regression\n",
    "\n",
    "\n",
    "###\n",
    "#   function: predict_logistic_regression\n",
    "#       @param: input_x => training dataset features\n",
    "#       @param: input_y => training dataset label\n",
    "#       @param: input_z => testing dataset records (features only)\n",
    "#   \n",
    "#   output: array/list of predicted result of input_z\n",
    "###\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "def predict_logistic_regression(input_x, input_y, input_z):\n",
    "    # build the model based on training data\n",
    "    model.fit(input_x, input_y)\n",
    "\n",
    "    # insert testing dataset to get the predicted output\n",
    "    predicted_values = model.predict(input_z)\n",
    "\n",
    "    return predicted_values\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Applying 5-fold-cross-validation\n",
    "k = 5\n",
    "kf = KFold(n_splits = k, random_state = None)\n",
    "\n",
    "\n",
    "# A function to run 5-fold cross validation on polynomial_logistic_regression\n",
    "def kFold_logistic_regression(input_X, input_Y):\n",
    "\n",
    "    validation_f1_score = []\n",
    "\n",
    "    for train_index , validation_index in kf.split(input_X):\n",
    "\n",
    "        # print('Start model fitting, k=', train_index[0], ' - ', train_index[-1], ' ...')\n",
    "\n",
    "        X_train , X_valid = input_X.iloc[train_index,:], input_X.iloc[validation_index,:]\n",
    "        y_train, y_valid = input_Y.iloc[train_index], input_Y.iloc[validation_index]\n",
    "\n",
    "        # print('X_train: ', X_train)\n",
    "\n",
    "        y_train = y_train.to_numpy().ravel()\n",
    "        y_valid = y_valid.to_numpy().ravel()\n",
    "        \n",
    "        pred_testValues = predict_logistic_regression(X_train, y_train, X_valid)\n",
    "\n",
    "        # count the f1 score(true records / predicted records)\n",
    "        valid_f1 = f1_score(y_valid, pred_testValues)\n",
    "        validation_f1_score.append(valid_f1)\n",
    "\n",
    "    return validation_f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.33333333333333337\n",
      "0.924731182795699\n",
      "0.8372093023255813\n",
      "0.717948717948718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.703305634100833"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_f1 = []\n",
    "\n",
    "testing_f1_score = kFold_logistic_regression(df_X, df_Y)\n",
    "\n",
    "\n",
    "# print('testing set F1 score (poly 2 to 12) under 5-fold-cross-validation: ')\n",
    "for item in testing_f1_score:\n",
    "    print(item)\n",
    "    if item != 0.0:\n",
    "        mean_f1.append(item)\n",
    "    \n",
    "np.mean(mean_f1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Real prediction on testing data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filePath: ../result_folder/logisticV6_threshold_0d82.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "url_test = 'https://raw.githubusercontent.com/lucascheng24/comp4432ML-Dont-over-fit-II/main/test.csv'\n",
    "df_test = pd.read_csv(url_test, index_col=\"id\")\n",
    "\n",
    "# implement feature reduction\n",
    "if implement_feature_reduction == True:\n",
    "    test_features_list = list_remainingFeatures\n",
    "    if 'target' in test_features_list:\n",
    "        test_features_list.remove('target')\n",
    "        df_test = df_test[test_features_list]\n",
    "\n",
    "pred_values = predict_logistic_regression(df_X, df_Y, df_test)\n",
    "\n",
    "\n",
    "specific_req_str = ''\n",
    "\n",
    "if adding_sample_on_class_0:\n",
    "    specific_req_str += '_' + str(adjusted_percentage_range).replace(\".\", \"d\") + 'pct'\n",
    "\n",
    "if implement_feature_reduction:\n",
    "    specific_req_str += '_threshold_' + str(feature_reduction_threshold).replace(\".\", \"d\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filePath = '../result_folder/logisticV6' + specific_req_str +'.csv'\n",
    "\n",
    "\n",
    "print(\"filePath:\", filePath)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filePath, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"id\", \"target\"])\n",
    "    for i in range(250, 20000):\n",
    "        writer.writerow([i, pred_values[i-250]])\n",
    "    file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
