{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>logistic regression without applying polynomin</h1>\n",
    "# this one should use less RAM than last version(v001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "# df = pd.read_csv('./train.csv', index_col = True)\n",
    "url = 'https://raw.githubusercontent.com/lucascheng24/comp4432ML-Dont-over-fit-II/main/train.csv'\n",
    "df = pd.read_csv(url, index_col=\"id\")\n",
    "df['target'] = df['target'].astype(int)\n",
    "\n",
    "parameters_dictionary = {}\n",
    "\n",
    "for element in df:\n",
    "    if element != \"target\":\n",
    "        parameters_dictionary.update({element : df[element]})\n",
    "\n",
    "\n",
    "\n",
    "label_dictionary = {'label': df['target']}\n",
    "\n",
    "df_X = pd.DataFrame(data = parameters_dictionary)\n",
    "df_Y = pd.DataFrame(data = label_dictionary)\n",
    "\n",
    "\n",
    "# print(df_Y)\n",
    "\n",
    "# print(df_Y.groupby('label').size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement logistic regression\n",
    "\n",
    "\n",
    "###\n",
    "#   function: predict_logistic_regression\n",
    "#       @param: input_x => training dataset features\n",
    "#       @param: input_y => training dataset label\n",
    "#       @param: input_z => testing dataset records (features only)\n",
    "#   \n",
    "#   output: array/list of predicted result of input_z\n",
    "###\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "def predict_logistic_regression(input_x, input_y, input_z):\n",
    "    # build the model based on training data\n",
    "    model.fit(input_x, input_y)\n",
    "\n",
    "    # insert testing dataset to get the predicted output\n",
    "    predicted_values = model.predict(input_z)\n",
    "\n",
    "    return predicted_values\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Applying 5-fold-cross-validation\n",
    "k = 5\n",
    "kf = KFold(n_splits = k, random_state = None)\n",
    "\n",
    "\n",
    "# A function to run 5-fold cross validation on polynomial_logistic_regression\n",
    "def kFold_logistic_regression(input_X, input_Y):\n",
    "\n",
    "    validation_f1_score = []\n",
    "\n",
    "    for train_index , validation_index in kf.split(input_X):\n",
    "\n",
    "        # print('Start model fitting, k=', train_index[0], ' - ', train_index[-1], ' ...')\n",
    "\n",
    "        X_train , X_valid = input_X.iloc[train_index,:], input_X.iloc[validation_index,:]\n",
    "        y_train, y_valid = input_Y.iloc[train_index], input_Y.iloc[validation_index]\n",
    "\n",
    "        # print('X_train: ', X_train)\n",
    "\n",
    "        y_train = y_train.to_numpy().ravel()\n",
    "        y_valid = y_valid.to_numpy().ravel()\n",
    "        \n",
    "        pred_testValues = predict_logistic_regression(X_train, y_train, X_valid)\n",
    "\n",
    "        # count the f1 score(true records / predicted records)\n",
    "        valid_f1 = f1_score(y_valid, pred_testValues)\n",
    "        validation_f1_score.append(valid_f1)\n",
    "\n",
    "    return validation_f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8055555555555555, 0.8059701492537314, 0.7868852459016393, 0.71875, 0.7272727272727273]\n"
     ]
    }
   ],
   "source": [
    "testing_f1 = []\n",
    "\n",
    "testing_f1_score = kFold_logistic_regression(df_X, df_Y)\n",
    "testing_f1.append(testing_f1_score)\n",
    "\n",
    "\n",
    "# print('testing set F1 score (poly 2 to 12) under 5-fold-cross-validation: ')\n",
    "for row in testing_f1:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Real prediction on testing data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_test = 'https://raw.githubusercontent.com/lucascheng24/comp4432ML-Dont-over-fit-II/main/test.csv'\n",
    "df_test = pd.read_csv(url_test, index_col=\"id\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
